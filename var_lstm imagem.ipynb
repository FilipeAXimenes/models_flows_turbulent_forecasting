{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de carregamento dos dados: 0.13 segundos\n",
      "Número total de modos utilizados: 20\n",
      "Tempo de normalização dos dados: 0.02 segundos\n",
      "Tempo de preparação das sequências: 0.06 segundos\n",
      "Treinando um novo modelo...\n",
      "Epoch 1/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - loss: 0.1030 - val_loss: 0.0805\n",
      "Epoch 2/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0784 - val_loss: 0.0650\n",
      "Epoch 3/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0629 - val_loss: 0.0531\n",
      "Epoch 4/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0528 - val_loss: 0.0446\n",
      "Epoch 5/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.0451 - val_loss: 0.0382\n",
      "Epoch 6/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0396 - val_loss: 0.0334\n",
      "Epoch 7/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - loss: 0.0363 - val_loss: 0.0296\n",
      "Epoch 8/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.0329 - val_loss: 0.0270\n",
      "Epoch 9/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0315 - val_loss: 0.0249\n",
      "Epoch 10/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0302 - val_loss: 0.0234\n",
      "Epoch 11/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0291 - val_loss: 0.0221\n",
      "Epoch 12/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - loss: 0.0284 - val_loss: 0.0212\n",
      "Epoch 13/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 94ms/step - loss: 0.0275 - val_loss: 0.0205\n",
      "Epoch 14/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 0.0269 - val_loss: 0.0196\n",
      "Epoch 15/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0264 - val_loss: 0.0190\n",
      "Epoch 16/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 0.0259 - val_loss: 0.0184\n",
      "Epoch 17/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0255 - val_loss: 0.0179\n",
      "Epoch 18/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 0.0250 - val_loss: 0.0175\n",
      "Epoch 19/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0245 - val_loss: 0.0171\n",
      "Epoch 20/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 0.0241 - val_loss: 0.0168\n",
      "Epoch 21/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0242 - val_loss: 0.0163\n",
      "Epoch 22/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.0239 - val_loss: 0.0161\n",
      "Epoch 23/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0235 - val_loss: 0.0158\n",
      "Epoch 24/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0236 - val_loss: 0.0155\n",
      "Epoch 25/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0233 - val_loss: 0.0153\n",
      "Epoch 26/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - loss: 0.0231 - val_loss: 0.0150\n",
      "Epoch 27/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0228 - val_loss: 0.0148\n",
      "Epoch 28/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0230 - val_loss: 0.0146\n",
      "Epoch 29/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0227 - val_loss: 0.0143\n",
      "Epoch 30/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0227 - val_loss: 0.0141\n",
      "Epoch 31/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 0.0223 - val_loss: 0.0140\n",
      "Epoch 32/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - loss: 0.0221 - val_loss: 0.0138\n",
      "Epoch 33/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - loss: 0.0218 - val_loss: 0.0137\n",
      "Epoch 34/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 135ms/step - loss: 0.0218 - val_loss: 0.0134\n",
      "Epoch 35/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.0216 - val_loss: 0.0134\n",
      "Epoch 36/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.0215 - val_loss: 0.0132\n",
      "Epoch 37/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - loss: 0.0215 - val_loss: 0.0130\n",
      "Epoch 38/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 141ms/step - loss: 0.0215 - val_loss: 0.0129\n",
      "Epoch 39/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 130ms/step - loss: 0.0212 - val_loss: 0.0127\n",
      "Epoch 40/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.0215 - val_loss: 0.0126\n",
      "Epoch 41/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 132ms/step - loss: 0.0210 - val_loss: 0.0125\n",
      "Epoch 42/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - loss: 0.0210 - val_loss: 0.0124\n",
      "Epoch 43/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 100ms/step - loss: 0.0210 - val_loss: 0.0123\n",
      "Epoch 44/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - loss: 0.0206 - val_loss: 0.0121\n",
      "Epoch 45/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - loss: 0.0209 - val_loss: 0.0120\n",
      "Epoch 46/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - loss: 0.0210 - val_loss: 0.0119\n",
      "Epoch 47/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - loss: 0.0204 - val_loss: 0.0117\n",
      "Epoch 48/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - loss: 0.0209 - val_loss: 0.0116\n",
      "Epoch 49/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0205 - val_loss: 0.0114\n",
      "Epoch 50/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - loss: 0.0206 - val_loss: 0.0114\n",
      "Epoch 51/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - loss: 0.0206 - val_loss: 0.0112\n",
      "Epoch 52/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - loss: 0.0200 - val_loss: 0.0110\n",
      "Epoch 53/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.0200 - val_loss: 0.0106\n",
      "Epoch 54/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - loss: 0.0198 - val_loss: 0.0104\n",
      "Epoch 55/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0194 - val_loss: 0.0100\n",
      "Epoch 56/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0193 - val_loss: 0.0098\n",
      "Epoch 57/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0192 - val_loss: 0.0096\n",
      "Epoch 58/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0192 - val_loss: 0.0096\n",
      "Epoch 59/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0187 - val_loss: 0.0094\n",
      "Epoch 60/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0186 - val_loss: 0.0093\n",
      "Epoch 61/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0188 - val_loss: 0.0092\n",
      "Epoch 62/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0189 - val_loss: 0.0092\n",
      "Epoch 63/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0190 - val_loss: 0.0091\n",
      "Epoch 64/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0189 - val_loss: 0.0091\n",
      "Epoch 65/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0187 - val_loss: 0.0090\n",
      "Epoch 66/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0188 - val_loss: 0.0089\n",
      "Epoch 67/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0181 - val_loss: 0.0089\n",
      "Epoch 68/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0182 - val_loss: 0.0088\n",
      "Epoch 69/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0184 - val_loss: 0.0088\n",
      "Epoch 70/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 229ms/step - loss: 0.0180 - val_loss: 0.0086\n",
      "Epoch 71/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - loss: 0.0183 - val_loss: 0.0087\n",
      "Epoch 72/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - loss: 0.0181 - val_loss: 0.0086\n",
      "Epoch 73/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 0.0181 - val_loss: 0.0085\n",
      "Epoch 74/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0178 - val_loss: 0.0085\n",
      "Epoch 75/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0180 - val_loss: 0.0085\n",
      "Epoch 76/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 132ms/step - loss: 0.0179 - val_loss: 0.0085\n",
      "Epoch 77/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0181 - val_loss: 0.0084\n",
      "Epoch 78/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 223ms/step - loss: 0.0176 - val_loss: 0.0084\n",
      "Epoch 79/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 99ms/step - loss: 0.0177 - val_loss: 0.0083\n",
      "Epoch 80/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - loss: 0.0178 - val_loss: 0.0083\n",
      "Epoch 81/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - loss: 0.0177 - val_loss: 0.0083\n",
      "Epoch 82/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - loss: 0.0178 - val_loss: 0.0082\n",
      "Epoch 83/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0178 - val_loss: 0.0082\n",
      "Epoch 84/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 135ms/step - loss: 0.0176 - val_loss: 0.0081\n",
      "Epoch 85/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 92ms/step - loss: 0.0179 - val_loss: 0.0081\n",
      "Epoch 86/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 121ms/step - loss: 0.0178 - val_loss: 0.0080\n",
      "Epoch 87/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - loss: 0.0177 - val_loss: 0.0081\n",
      "Epoch 88/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 119ms/step - loss: 0.0176 - val_loss: 0.0081\n",
      "Epoch 89/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0176 - val_loss: 0.0079\n",
      "Epoch 90/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - loss: 0.0179 - val_loss: 0.0079\n",
      "Epoch 91/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - loss: 0.0173 - val_loss: 0.0079\n",
      "Epoch 92/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - loss: 0.0174 - val_loss: 0.0079\n",
      "Epoch 93/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.0175 - val_loss: 0.0079\n",
      "Epoch 94/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0173 - val_loss: 0.0078\n",
      "Epoch 95/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0175 - val_loss: 0.0078\n",
      "Epoch 96/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 157ms/step - loss: 0.0175 - val_loss: 0.0078\n",
      "Epoch 97/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - loss: 0.0174 - val_loss: 0.0078\n",
      "Epoch 98/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - loss: 0.0172 - val_loss: 0.0078\n",
      "Epoch 99/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - loss: 0.0173 - val_loss: 0.0077\n",
      "Epoch 100/100\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - loss: 0.0173 - val_loss: 0.0076\n",
      "Tempo de treinamento do modelo LSTM: 372.52 segundos\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step\n",
      "Tempo de previsão do modelo LSTM: 5.40 segundos\n",
      "Tempo para reverter a normalização: 0.05 segundos\n",
      "Ordem do modelo VAR nos resíduos selecionada (AIC): 8\n",
      "Tempo de treinamento do modelo VAR: 43.00 segundos\n",
      "Tempo de previsão do modelo VAR: 0.01 segundos\n",
      "Métricas para a parte real (LSTM + VAR):\n",
      "MSE: 0.000000\n",
      "MAE: 0.000020\n",
      "R²: 0.999242\n",
      "Métricas para a parte imaginária (LSTM + VAR):\n",
      "MSE: 0.000000\n",
      "MAE: 0.000020\n",
      "R²: 0.999261\n",
      "Média do NMSE para a parte real (LSTM + VAR): 0.002522\n",
      "Média do NMSE para a parte imaginária (LSTM + VAR): 0.002540\n",
      "Média do NMSE para o módulo dos coeficientes (LSTM + VAR): 0.005860\n",
      "Tempo total de execução do script: 517.71 segundos\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.api import VAR\n",
    "import os\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Configurações gerais\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "# Diretório para salvar as figuras\n",
    "output_dir = 'figuras_lstm_var'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Atualizar os hiperparâmetros\n",
    "hyperparams = {\n",
    "    'model_path': 'modelo_lstm_var_hibrido.keras',\n",
    "    'num_coefs': 20,\n",
    "    'sequence_length': 50,\n",
    "    'lstm_units': 64,\n",
    "    'dropout_rate': 0.2,\n",
    "    'l2_regularization': 0.0001,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 100,\n",
    "    'batch_size': 64,\n",
    "    'early_stopping_patience': 10\n",
    "}\n",
    "\n",
    "# Medir o tempo total do script\n",
    "total_start_time = time.time()\n",
    "\n",
    "# Medir o tempo de carregamento dos dados\n",
    "start_time = time.time()\n",
    "\n",
    "# Carregar os arquivos .mat fornecidos\n",
    "file_path_temp_coefs = \"temp_coefs.mat\"\n",
    "file_path_spatial_modes = \"spatial_modes.mat\"\n",
    "file_path_mean_flow = \"mean_flow.mat\"\n",
    "file_path_parameters = \"parameters.mat\"\n",
    "\n",
    "# Carregar os coeficientes temporais\n",
    "mat_data_temp = sio.loadmat(file_path_temp_coefs)\n",
    "ts = mat_data_temp['ts'].flatten()  # Vetor de tempo\n",
    "coefs = mat_data_temp['coefs']      # Matriz de coeficientes complexos\n",
    "\n",
    "# Carregar os modos espaciais\n",
    "mat_data_spatial = sio.loadmat(file_path_spatial_modes)\n",
    "phi = mat_data_spatial['phi']       # Matriz de modos espaciais\n",
    "\n",
    "# Carregar o vetor y e a média Xavg\n",
    "mat_data_mean_flow = sio.loadmat(file_path_mean_flow)\n",
    "y_positions = mat_data_mean_flow['y'].flatten()  # Vetor de posições espaciais y\n",
    "Xavg = mat_data_mean_flow['Xavg'].flatten()      # Média do fluxo\n",
    "\n",
    "# Carregar os modos usados no POD\n",
    "mat_data_parameters = sio.loadmat(file_path_parameters)\n",
    "nmodos_pod = mat_data_parameters['nmodes']       # Modos usados no POD\n",
    "\n",
    "# Medir o tempo de carregamento dos dados\n",
    "end_time = time.time()\n",
    "print(f\"Tempo de carregamento dos dados: {end_time - start_time:.2f} segundos\")\n",
    "\n",
    "# Definir o número de coeficientes a serem utilizados\n",
    "num_coefs = hyperparams['num_coefs']\n",
    "print(f\"Número total de modos utilizados: {num_coefs}\")\n",
    "\n",
    "# Separar os coeficientes em parte real e imaginária\n",
    "real_coefs = np.real(coefs[:num_coefs, :])\n",
    "imag_coefs = np.imag(coefs[:num_coefs, :])\n",
    "\n",
    "# Concatenar as partes real e imaginária\n",
    "coefs_combined = np.vstack([real_coefs, imag_coefs])  # Dimensão (num_coefs*2, N)\n",
    "\n",
    "# Transpor para ter a forma (N, num_coefs*2)\n",
    "coefs_combined = coefs_combined.T\n",
    "\n",
    "# Definir o limite do primeiro intervalo\n",
    "first_interval_end = 4801  # Posição correspondente ao tempo 1300\n",
    "\n",
    "# Subamostragem para taxa de 0.5 (pegando a cada 2 pontos)\n",
    "train_data = coefs_combined[:first_interval_end:2]\n",
    "val_data = coefs_combined[first_interval_end:]\n",
    "\n",
    "# Normalizar os dados de treinamento e validação\n",
    "start_time = time.time()\n",
    "\n",
    "scalers = []\n",
    "train_data_normalized = np.zeros_like(train_data)\n",
    "val_data_normalized = np.zeros_like(val_data)\n",
    "\n",
    "num_total_coefs = num_coefs * 2\n",
    "\n",
    "for i in range(num_total_coefs):\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    train_data_normalized[:, i] = scaler.fit_transform(train_data[:, i].reshape(-1, 1)).flatten()\n",
    "    val_data_normalized[:, i] = scaler.transform(val_data[:, i].reshape(-1, 1)).flatten()\n",
    "    scalers.append(scaler)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Tempo de normalização dos dados: {end_time - start_time:.2f} segundos\")\n",
    "\n",
    "# Preparar os dados para a LSTM\n",
    "start_time = time.time()\n",
    "\n",
    "def create_sequences(input_data, seq_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    num_samples = len(input_data) - seq_length\n",
    "    for i in range(num_samples):\n",
    "        X_seq = input_data[i:i+seq_length]\n",
    "        y_seq = input_data[i+seq_length]\n",
    "        X.append(X_seq)\n",
    "        y.append(y_seq)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "sequence_length = hyperparams['sequence_length']\n",
    "X_train_lstm, y_train_lstm = create_sequences(train_data_normalized, sequence_length)\n",
    "X_val_lstm, y_val_lstm = create_sequences(val_data_normalized, sequence_length)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Tempo de preparação das sequências: {end_time - start_time:.2f} segundos\")\n",
    "\n",
    "# Verificar se o modelo já foi salvo anteriormente\n",
    "retrain_model = True\n",
    "model_path = hyperparams['model_path']\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Carregando o modelo salvo...\")\n",
    "    model = load_model(model_path)\n",
    "    if model.input_shape[1:] != (X_train_lstm.shape[1], X_train_lstm.shape[2]):\n",
    "        print(\"O modelo salvo não é compatível com os dados atuais. Treinando um novo modelo.\")\n",
    "        os.remove(model_path)\n",
    "        retrain_model = True\n",
    "    else:\n",
    "        retrain_model = False\n",
    "else:\n",
    "    print(\"Treinando um novo modelo...\")\n",
    "    retrain_model = True\n",
    "\n",
    "if retrain_model:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Definir o modelo LSTM\n",
    "    lstm_input = Input(shape=(X_train_lstm.shape[1], X_train_lstm.shape[2]))\n",
    "    x = LSTM(hyperparams['lstm_units'], activation='tanh',\n",
    "             kernel_regularizer=l2(hyperparams['l2_regularization']),\n",
    "             recurrent_dropout=hyperparams['dropout_rate'])(lstm_input)\n",
    "    x = Dropout(hyperparams['dropout_rate'])(x)\n",
    "    output = Dense(num_total_coefs, activation='linear')(x)\n",
    "\n",
    "    # Definir e compilar o modelo\n",
    "    model = Model(inputs=lstm_input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=hyperparams['learning_rate']), loss='mean_squared_error')\n",
    "\n",
    "    # Definir callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=hyperparams['early_stopping_patience'],\n",
    "                                   restore_best_weights=True)\n",
    "    checkpoint = ModelCheckpoint('best_model_lstm.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "    # Treinar o modelo\n",
    "    history = model.fit(X_train_lstm, y_train_lstm,\n",
    "                        epochs=hyperparams['epochs'],\n",
    "                        batch_size=hyperparams['batch_size'],\n",
    "                        validation_data=(X_val_lstm, y_val_lstm),\n",
    "                        callbacks=[early_stopping, checkpoint],\n",
    "                        verbose=1)\n",
    "\n",
    "    # Salvar o modelo treinado\n",
    "    model.save(model_path)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Tempo de treinamento do modelo LSTM: {end_time - start_time:.2f} segundos\")\n",
    "else:\n",
    "    print(\"Usando o modelo salvo para fazer previsões.\")\n",
    "\n",
    "# Medir o tempo de previsão da LSTM\n",
    "start_time = time.time()\n",
    "lstm_predictions_normalized = model.predict(X_val_lstm)\n",
    "end_time = time.time()\n",
    "print(f\"Tempo de previsão do modelo LSTM: {end_time - start_time:.2f} segundos\")\n",
    "\n",
    "# Reverter a normalização das previsões da LSTM\n",
    "start_time = time.time()\n",
    "lstm_predictions = np.zeros_like(lstm_predictions_normalized)\n",
    "for i in range(num_total_coefs):\n",
    "    scaler = scalers[i]\n",
    "    lstm_predictions[:, i] = scaler.inverse_transform(lstm_predictions_normalized[:, i].reshape(-1, 1)).flatten()\n",
    "end_time = time.time()\n",
    "print(f\"Tempo para reverter a normalização: {end_time - start_time:.2f} segundos\")\n",
    "\n",
    "# Calcular os resíduos entre os valores reais e as previsões da LSTM\n",
    "actual_values = val_data[sequence_length:]\n",
    "residuals = actual_values - lstm_predictions\n",
    "\n",
    "# Ajustar o modelo VAR nos resíduos\n",
    "start_time = time.time()\n",
    "model_var = VAR(residuals)\n",
    "# Selecionar automaticamente a ordem do modelo (número de defasagens) usando o critério AIC\n",
    "results_aic = model_var.select_order(maxlags=15)\n",
    "selected_lag = results_aic.aic\n",
    "print(f\"Ordem do modelo VAR nos resíduos selecionada (AIC): {selected_lag}\")\n",
    "model_var_fitted = model_var.fit(selected_lag)\n",
    "end_time = time.time()\n",
    "print(f\"Tempo de treinamento do modelo VAR: {end_time - start_time:.2f} segundos\")\n",
    "\n",
    "# Previsões do VAR nos resíduos\n",
    "start_time = time.time()\n",
    "var_residuals_pred = model_var_fitted.fittedvalues\n",
    "# Preencher o início com zeros para alinhamento\n",
    "var_residuals_pred = np.vstack([np.zeros((selected_lag, num_total_coefs)), var_residuals_pred])\n",
    "end_time = time.time()\n",
    "print(f\"Tempo de previsão do modelo VAR: {end_time - start_time:.2f} segundos\")\n",
    "\n",
    "# Previsão final = Previsão LSTM + Previsão VAR nos resíduos\n",
    "final_predictions = lstm_predictions[selected_lag:] + var_residuals_pred[selected_lag:]\n",
    "\n",
    "# Ajustar o tamanho das previsões finais para corresponder aos valores reais\n",
    "min_length = min(final_predictions.shape[0], actual_values.shape[0])\n",
    "final_predictions = final_predictions[:min_length]\n",
    "actual_values = actual_values[selected_lag:][:min_length]\n",
    "\n",
    "# Separar as partes real e imaginária das previsões e valores reais\n",
    "pred_real = final_predictions[:, :num_coefs]\n",
    "pred_imag = final_predictions[:, num_coefs:]\n",
    "actual_real = actual_values[:, :num_coefs]\n",
    "actual_imag = actual_values[:, num_coefs:]\n",
    "\n",
    "# Reconstruir os coeficientes complexos preditos e reais\n",
    "predicted_coefs = pred_real + 1j * pred_imag\n",
    "actual_coefs = actual_real + 1j * actual_imag\n",
    "\n",
    "# Reconstruir X a partir dos coeficientes preditos e dos modos espaciais\n",
    "phi_reduced = phi[:, :num_coefs]  # Dimensão (387, num_coefs)\n",
    "Xavg = Xavg.flatten()  # Dimensão (387,)\n",
    "\n",
    "X_rec_list = []\n",
    "X_actual_list = []\n",
    "\n",
    "for i in range(predicted_coefs.shape[0]):\n",
    "    # Reconstrução predita\n",
    "    X_rec = Xavg + phi_reduced @ predicted_coefs[i]\n",
    "    X_rec_list.append(X_rec)\n",
    "    # Reconstrução real\n",
    "    X_actual = Xavg + phi_reduced @ actual_coefs[i]\n",
    "    X_actual_list.append(X_actual)\n",
    "\n",
    "# Converter as listas em arrays e transpor\n",
    "X_rec_array = np.array(X_rec_list).T        # Forma (387, num_samples)\n",
    "X_actual_array = np.array(X_actual_list).T  # Forma (387, num_samples)\n",
    "\n",
    "# Número de pontos em y\n",
    "ny = y_positions.shape[0]  # Deve ser 129\n",
    "\n",
    "# Plotar a comparação entre os perfis originais e reconstruídos de |u|\n",
    "step = 10  # Número de subplots (ajuste conforme necessário)\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.clf()\n",
    "for i in range(step):\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    # Índice do tempo\n",
    "    idx = i * (X_rec_array.shape[1] // step)\n",
    "    plt.plot(np.abs(X_actual_array[:ny, idx]), y_positions, label='Original')\n",
    "    plt.plot(np.abs(X_rec_array[:ny, idx]), y_positions, label='Reconstruído', linestyle='--')\n",
    "    plt.xlabel('|u|')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(f'Amostra {idx}')\n",
    "    plt.grid(True)\n",
    "    if i == 0:\n",
    "        plt.legend()\n",
    "plt.suptitle('Comparação de |u| Original e Reconstruído (Validação) - LSTM + VAR')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.savefig(os.path.join(output_dir, 'comparacao_u_original_reconstruido_lstm_var.png'), dpi=400)\n",
    "plt.close()\n",
    "\n",
    "# Calcular as métricas de erro separadamente para as partes real e imaginária\n",
    "mse_real = mean_squared_error(actual_real.flatten(), pred_real.flatten())\n",
    "mae_real = mean_absolute_error(actual_real.flatten(), pred_real.flatten())\n",
    "r2_real = r2_score(actual_real.flatten(), pred_real.flatten())\n",
    "\n",
    "mse_imag = mean_squared_error(actual_imag.flatten(), pred_imag.flatten())\n",
    "mae_imag = mean_absolute_error(actual_imag.flatten(), pred_imag.flatten())\n",
    "r2_imag = r2_score(actual_imag.flatten(), pred_imag.flatten())\n",
    "\n",
    "print(f\"Métricas para a parte real (LSTM + VAR):\")\n",
    "print(f\"MSE: {mse_real:.6f}\")\n",
    "print(f\"MAE: {mae_real:.6f}\")\n",
    "print(f\"R²: {r2_real:.6f}\")\n",
    "\n",
    "print(f\"Métricas para a parte imaginária (LSTM + VAR):\")\n",
    "print(f\"MSE: {mse_imag:.6f}\")\n",
    "print(f\"MAE: {mae_imag:.6f}\")\n",
    "print(f\"R²: {r2_imag:.6f}\")\n",
    "\n",
    "# Função para calcular NMSE por coeficiente\n",
    "def calculate_normalized_mse(actual, predicted):\n",
    "    num_coefs = actual.shape[1]\n",
    "    nmse = np.zeros(num_coefs)\n",
    "    for c in range(num_coefs):\n",
    "        mse = mean_squared_error(actual[:, c], predicted[:, c])\n",
    "        variance = np.var(actual[:, c])\n",
    "        # Evitar divisão por zero\n",
    "        if variance != 0:\n",
    "            nmse[c] = mse / variance\n",
    "        else:\n",
    "            nmse[c] = np.nan  # ou trate conforme apropriado\n",
    "    return nmse\n",
    "\n",
    "# Calcular NMSE para a parte real\n",
    "nmse_real = calculate_normalized_mse(actual_real, pred_real)\n",
    "\n",
    "# Calcular NMSE para a parte imaginária\n",
    "nmse_imag = calculate_normalized_mse(actual_imag, pred_imag)\n",
    "\n",
    "# Calcular NMSE para o módulo dos coeficientes\n",
    "actual_modulus = np.sqrt(actual_real**2 + actual_imag**2)\n",
    "predicted_modulus = np.sqrt(pred_real**2 + pred_imag**2)\n",
    "nmse_modulus = calculate_normalized_mse(actual_modulus, predicted_modulus)\n",
    "\n",
    "# Calcular a média do NMSE sobre todos os coeficientes\n",
    "average_nmse_real = np.nanmean(nmse_real)\n",
    "average_nmse_imag = np.nanmean(nmse_imag)\n",
    "average_nmse_modulus = np.nanmean(nmse_modulus)\n",
    "\n",
    "print(f\"Média do NMSE para a parte real (LSTM + VAR): {average_nmse_real:.6f}\")\n",
    "print(f\"Média do NMSE para a parte imaginária (LSTM + VAR): {average_nmse_imag:.6f}\")\n",
    "print(f\"Média do NMSE para o módulo dos coeficientes (LSTM + VAR): {average_nmse_modulus:.6f}\")\n",
    "\n",
    "# Plotar NMSE do Módulo por coeficiente\n",
    "coefficients = np.arange(1, num_coefs + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(coefficients, nmse_modulus, width=0.6, label='Módulo (LSTM + VAR)', color='orange')\n",
    "plt.xlabel('Índice do Coeficiente')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('NMSE por Coeficiente (Módulo) - LSTM + VAR')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(output_dir, 'nmse_por_coeficiente_modulo_lstm_var.png'), dpi=400)\n",
    "plt.close()\n",
    "\n",
    "# Plotar a função de perda (loss) ao longo das épocas\n",
    "if retrain_model:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Perda de Treinamento')\n",
    "    plt.plot(history.history['val_loss'], label='Perda de Validação')\n",
    "    plt.title('Função de Perda ao Longo das Épocas - LSTM')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Perda (MSE)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(output_dir, 'funcao_perda_lstm_var.png'), dpi=400)\n",
    "    plt.close()\n",
    "\n",
    "# Plotar NMSE para a parte real, imaginária e módulo dos coeficientes\n",
    "coefficients = np.arange(1, num_coefs + 1)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# NMSE da Parte Real\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.bar(coefficients, nmse_real, width=0.6, color='blue')\n",
    "plt.xlabel('Índice do Coeficiente')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('NMSE por Coeficiente - Parte Real (LSTM + VAR)')\n",
    "plt.grid(True)\n",
    "\n",
    "# NMSE da Parte Imaginária\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.bar(coefficients, nmse_imag, width=0.6, color='green')\n",
    "plt.xlabel('Índice do Coeficiente')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('NMSE por Coeficiente - Parte Imaginária (LSTM + VAR)')\n",
    "plt.grid(True)\n",
    "\n",
    "# NMSE do Módulo\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.bar(coefficients, nmse_modulus, width=0.6, color='orange')\n",
    "plt.xlabel('Índice do Coeficiente')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('NMSE por Coeficiente - Módulo (LSTM + VAR)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'nmse_por_coeficiente_todas_lstm_var.png'), dpi=400)\n",
    "plt.close()\n",
    "\n",
    "# Adicionar a plotagem da evolução do NMSE ao longo do tempo\n",
    "nmse_time = np.mean((actual_values - final_predictions)**2, axis=1) / np.var(actual_values, axis=0).mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(nmse_time, label='NMSE ao Longo do Tempo')\n",
    "plt.xlabel('Amostra de Tempo')\n",
    "plt.ylabel('NMSE')\n",
    "plt.title('Evolução do NMSE ao Longo das Amostras de Tempo - LSTM + VAR')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(output_dir, 'nmse_tempo_lstm_var.png'), dpi=400)\n",
    "plt.close()\n",
    "\n",
    "# Plotar a comparação dos perfis de velocidade 'v' e 'w' originais e reconstruídos\n",
    "\n",
    "# Exemplo para 'v'\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.clf()\n",
    "for i in range(step):\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    idx = i * (X_rec_array.shape[1] // step)\n",
    "    plt.plot(np.abs(X_actual_array[ny:2*ny, idx]), y_positions, label='Original')\n",
    "    plt.plot(np.abs(X_rec_array[ny:2*ny, idx]), y_positions, label='Reconstruído', linestyle='--')\n",
    "    plt.xlabel('|v|')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(f'Amostra {idx}')\n",
    "    plt.grid(True)\n",
    "    if i == 0:\n",
    "        plt.legend()\n",
    "plt.suptitle('Comparação de |v| Original e Reconstruído (Validação) - LSTM + VAR')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.savefig(os.path.join(output_dir, 'comparacao_v_original_reconstruido_lstm_var.png'), dpi=400)\n",
    "plt.close()\n",
    "\n",
    "# Exemplo para 'w'\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.clf()\n",
    "for i in range(step):\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    idx = i * (X_rec_array.shape[1] // step)\n",
    "    plt.plot(np.abs(X_actual_array[2*ny:, idx]), y_positions, label='Original')\n",
    "    plt.plot(np.abs(X_rec_array[2*ny:, idx]), y_positions, label='Reconstruído', linestyle='--')\n",
    "    plt.xlabel('|w|')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(f'Amostra {idx}')\n",
    "    plt.grid(True)\n",
    "    if i == 0:\n",
    "        plt.legend()\n",
    "plt.suptitle('Comparação de |w| Original e Reconstruído (Validação) - LSTM + VAR')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.savefig(os.path.join(output_dir, 'comparacao_w_original_reconstruido_lstm_var.png'), dpi=400)\n",
    "plt.close()\n",
    "\n",
    "# Plotar coeficientes aleatórios em subplots\n",
    "num_plots = 4  # Número de coeficientes a serem plotados\n",
    "random_indices = np.random.choice(num_coefs, num_plots, replace=False)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for idx, coef_index in enumerate(random_indices):\n",
    "    plt.subplot(2, 2, idx + 1)\n",
    "    plt.plot(actual_real[:, coef_index], label=f'Parte Real - Coeficiente {coef_index+1} (Real)')\n",
    "    plt.plot(pred_real[:, coef_index], label=f'Parte Real - Coeficiente {coef_index+1} (Predito)', linestyle='--')\n",
    "    plt.title(f'Comparação da Parte Real do Coeficiente {coef_index+1} (Validação) - LSTM + VAR')\n",
    "    plt.xlabel('Amostra de Tempo')\n",
    "    plt.ylabel('Valor')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'comparacao_parte_real_coeficientes_lstm_var.png'), dpi=400)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for idx, coef_index in enumerate(random_indices):\n",
    "    plt.subplot(2, 2, idx + 1)\n",
    "    plt.plot(actual_imag[:, coef_index], label=f'Parte Imaginária - Coeficiente {coef_index+1} (Real)')\n",
    "    plt.plot(pred_imag[:, coef_index], label=f'Parte Imaginária - Coeficiente {coef_index+1} (Predito)', linestyle='--')\n",
    "    plt.title(f'Comparação da Parte Imaginária do Coeficiente {coef_index+1} (Validação) - LSTM + VAR')\n",
    "    plt.xlabel('Amostra de Tempo')\n",
    "    plt.ylabel('Valor')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'comparacao_parte_imaginaria_coeficientes_lstm_var.png'), dpi=400)\n",
    "plt.close()\n",
    "\n",
    "# Exibir o tempo total de execução do script\n",
    "total_end_time = time.time()\n",
    "print(f\"Tempo total de execução do script: {total_end_time - total_start_time:.2f} segundos\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
